{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"hW6NYvRZbF84"},"outputs":[],"source":["%pip install jsonlines\n","\n","clear_output()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OTgt3npOK0xh"},"outputs":[],"source":["import os\n","import subprocess\n","import threading\n","from IPython.display import clear_output\n","import jsonlines\n","import requests\n","import json"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9NJST07hk4CC","executionInfo":{"status":"ok","timestamp":1738303219578,"user_tz":300,"elapsed":38332,"user":{"displayName":"Prasun Dhungana","userId":"15869599958843435384"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9aba8e49-d318-4eb8-c5ac-3ebdd1bd4077"},"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","pciutils is already the newest version (1:3.7.0-6).\n","0 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n",">>> Cleaning up old version at /usr/local/lib/ollama\n",">>> Installing ollama to /usr/local\n",">>> Downloading Linux amd64 bundle\n","############################################################################################# 100.0%\n",">>> Adding ollama user to video group...\n",">>> Adding current user to ollama group...\n",">>> Creating ollama systemd service...\n","\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",">>> The Ollama API is now available at 127.0.0.1:11434.\n",">>> Install complete. Run \"ollama\" from the command line.\n","\u001b[1m\u001b[31mWARNING:\u001b[m No NVIDIA/AMD GPU detected. Ollama will run in CPU-only mode.\n",">>> The Ollama API is now available at 127.0.0.1:11434.\n",">>> Install complete. Run \"ollama\" from the command line.\n"]}],"source":["# Install necessary packages\n","!sudo apt-get install -y pciutils\n","!curl -fsSL https://ollama.com/install.sh | sh  # Download Ollama API\n","\n","# Start the Ollama API server in a separate thread\n","def ollama():\n","    os.environ['OLLAMA_HOST'] = '0.0.0.0:11434'  # localhost\n","    os.environ['OLLAMA_ORIGINS'] = '*'  # Allow all origins\n","    subprocess.Popen([\"ollama\", \"serve\"])\n","\n","ollama_thread = threading.Thread(target=ollama)\n","ollama_thread.start()\n","\n","# clear_output()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MMbLvpB-pcX4"},"outputs":[],"source":["# !ollama pull llama3.1:70b\n","!ollama pull phi4\n","clear_output()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":629,"status":"ok","timestamp":1738303163991,"user":{"displayName":"Prasun Dhungana","userId":"15869599958843435384"},"user_tz":300},"id":"NKSzpLrGtRlk","outputId":"bf2342ae-7a12-44f8-dfd4-c15726dc0527"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":204,"status":"ok","timestamp":1738303165911,"user":{"displayName":"Prasun Dhungana","userId":"15869599958843435384"},"user_tz":300},"id":"p4lBAANPyWd1","outputId":"72e2d2f7-67c0-4da6-b7e0-660e039f92d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/SemEval_Task10\n","\u001b[0m\u001b[01;34mdev-documents_4_December\u001b[0m/                \u001b[01;34msubtask-1-results\u001b[0m/          training_data.jsonl\n","\u001b[01;34msemeval2025task10-scorers-baselines-v2\u001b[0m/  \u001b[01;34mtarget_4_December_release\u001b[0m/\n","SemEval-Task10-Subtask01.ipynb           \u001b[01;34mtestdata_ST12\u001b[0m/\n"]}],"source":["%cd /content/drive/MyDrive/SemEval_Task10\n","%ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jDaiNwuGIBWc"},"outputs":[],"source":["def load_data(language_folder):\n","    articles_folder = os.path.join(language_folder, \"subtask-1-documents\")\n","    entity_file = os.path.join(language_folder, \"subtask-1-entity-mentions.txt\")\n","    data = []\n","\n","    # Load articles and entities\n","    for article_file in os.listdir(articles_folder):\n","        if '(' not in article_file:\n","          article_path = os.path.join(articles_folder, article_file)\n","          with open(article_path, 'r') as file:\n","              article_text = file.read()\n","\n","          # Load corresponding entities with indices\n","          with open(entity_file, 'r') as file:\n","              entities = [\n","                  {\n","                      \"entity_name\": line.strip().split('\\t')[1],  # Extract entity name\n","                      \"start_index\": int(line.strip().split('\\t')[2]),  # Extract start index\n","                      \"end_index\": int(line.strip().split('\\t')[3])    # Extract end index\n","                  }\n","                  for line in file.readlines()\n","                  if line.startswith(article_file)\n","              ]\n","\n","          for entity in entities:\n","              article_id = article_file + \".txt\" if \".txt\" not in article_file else article_file\n","              entity_name = entity[\"entity_name\"]\n","              start_index = entity[\"start_index\"]\n","              end_index = entity[\"end_index\"]\n","              data.append({\"article_id\": article_file,\n","                           \"article_text\": article_text,\n","                           \"entity_name\": entity_name,\n","                           \"start_index\": start_index,\n","                           \"end_index\": end_index})\n","\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tfaMPTh6IqyB"},"outputs":[],"source":["def classify_entities(article_id, article_text, entity_name, api_url=\"http://0.0.0.0:11434\"):\n","\n","    # print(f\"{article_id} {entity_name}\")\n","    prompt = (\n","    f\"Given the article with articleID {article_id}:\\n'{article_text}'\\n\"\n","    f\"and the entity: {entity_name}, classify the entity into one of the following **primary roles**:\\n\"\n","    f\"- 'Protagonist'\\n\"\n","    f\"- 'Antagonist'\\n\"\n","    f\"- 'Innocent'\\n\\n\"\n","    f\"The classification must reflect the author's sentiment toward the entity as expressed in the article.\\n\\n\"\n","    f\"Next, assign one or more **fine-grained roles**, strictly chosen from the list associated with the assigned primary role:\\n\"\n","    f\"- **Protagonist**: ['Guardian', 'Martyr', 'Peacemaker', 'Rebel', 'Underdog', 'Virtuous']\\n\"\n","    f\"- **Antagonist**: ['Instigator', 'Conspirator', 'Tyrant', 'Foreign Adversary', 'Traitor', 'Spy', \"\n","    f\"'Saboteur', 'Corrupt', 'Incompetent', 'Terrorist', 'Deceiver', 'Bigot']\\n\"\n","    f\"- **Innocent**: ['Forgotten', 'Exploited', 'Victim', 'Scapegoat']\\n\\n\"\n","    f\"**Important Requirements:**\\n\"\n","    f\"1. Assign exactly one **primary role** ('Protagonist', 'Antagonist', or 'Innocent').\\n\"\n","    f\"2. Assign one or more **fine-grained roles**, strictly from the associated list above.\\n\"\n","    f\"3. Do not invent or use roles that are not listed above.\\n\"\n","    f\"4. Do not leave the primary role or fine-grained roles empty or undefined.\\n\\n\"\n","    f\"**Failure Examples:**\\n\"\n","    f\"- Assigning a primary role not listed (e.g., 'Neutral').\\n\"\n","    f\"- Assigning fine-grained roles not listed (e.g., 'Aggressor', 'Fascist Leader', 'Extremist', 'Scam', 'Expansionist', 'Imperialist', 'Military', 'Propagandists', etc.\\n\"\n","    f\"- Leaving the fine-grained roles empty.\\n\\n\"\n","    f\"Make sure that the classification strictly follows these rules. Your response should only include the assigned **primary role** and the corresponding **fine-grained roles**.\"\n",")\n","\n","\n","    response = requests.post(\n","    url=f\"{api_url}/api/generate\",\n","    json={\n","        \"model\": \"gemma2\",\n","        \"prompt\": prompt,\n","        \"stream\": False,\n","        \"format\": {\n","            \"type\": \"object\",\n","            \"properties\": {\n","                \"primary_role\": {\n","                    \"type\": \"string\"\n","                },\n","                \"fine_grained_roles\": {\n","                    \"type\": \"array\",\n","                    \"items\": {\n","                        \"type\": \"string\"\n","                    }\n","                }\n","            },\n","            \"required\": [\n","                \"primary_role\",\n","                \"fine_grained_roles\"\n","            ]\n","        }\n","    }\n",")\n","\n","    if response.status_code == 200:\n","        try:\n","            output = response.json()\n","            return output['response']\n","        except ValueError as e:\n","            print(f\"Failed for {article_id}\")\n","            print(\"Error:\", e)\n","    else:\n","        print(f\"API call failed for {article_id}, Status code: {response.status_code}\")\n","    return None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qa0DPHuXI6Ra"},"outputs":[],"source":["def process_language(language_folder, base_output_path):\n","    \"\"\"\n","    Process all articles in a given language folder. Classifies entities and saves results.\n","    \"\"\"\n","    language_code = os.path.basename(language_folder)\n","    language_output_path = os.path.join(base_output_path, language_code)\n","    os.makedirs(language_output_path, exist_ok=True)\n","\n","    data = load_data(language_folder)  # Load articles and entities with indices\n","    results = []\n","\n","    for item in data:\n","        article_id = item[\"article_id\"]\n","        article_text = item[\"article_text\"]\n","        entity_name = item[\"entity_name\"]\n","        start_index = item[\"start_index\"]\n","        end_index = item[\"end_index\"]\n","\n","        # Classify all entities at once\n","        result = classify_entities(article_id, article_text, entity_name)\n","        if result:\n","          result = json.loads(result)\n","          result[\"articleID\"] = article_id\n","          result[\"entity_name\"] = entity_name\n","          result[\"start_index\"] = start_index\n","          result[\"end_index\"] = end_index\n","          result = json.dumps(result)\n","\n","          results.append(result)\n","\n","          # print(result)\n","\n","        # break\n","\n","    # Save results to a text file\n","    output_file = os.path.join(language_output_path, f\"{language_code}_results.jsonl\")\n","    with jsonlines.open(output_file, mode='w') as writer:\n","        writer.write_all(results)\n","\n","    print(f\"Processed {language_code}, results saved to {output_file}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":482451,"status":"ok","timestamp":1738216242730,"user":{"displayName":"Prasun Dhungana","userId":"15869599958843435384"},"user_tz":300},"id":"PXswIwBOIBdK","outputId":"99e0c513-9231-4d06-92bd-ef2d7b9b2404"},"outputs":[{"output_type":"stream","name":"stdout","text":["Processed RU, results saved to /content/drive/MyDrive/SemEval_Task10/testdata_ST12/results/RU/RU_results.jsonl\n"]}],"source":["def main():\n","    base_path = \"/content/drive/MyDrive/SemEval_Task10/testdata_ST12/\"\n","    base_output_path = \"/content/drive/MyDrive/SemEval_Task10/testdata_ST12/results\"\n","    # languages = [\"EN\", \"BG\", \"HI\", \"PT\", \"RU\"]\n","    languages = [\"RU\"]\n","\n","    for lang in languages:\n","        language_folder = os.path.join(base_path, lang)\n","        process_language(language_folder, base_output_path)\n","\n","main()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":274,"status":"ok","timestamp":1738216401646,"user":{"displayName":"Prasun Dhungana","userId":"15869599958843435384"},"user_tz":300},"id":"hjAoYjDiRIn5","outputId":"a9ecdefe-3fd4-4895-a640-f316d67bf0ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["DONE with 214 lines\n"]}],"source":["import json\n","import re\n","\n","def clean_up_result(input_file, output_file):\n","    numLines = 0\n","    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n","        for line in infile:\n","            line = line.strip()\n","\n","            if line:\n","                # Parse the JSON object\n","                try:\n","                    entity_data = json.loads(json.loads(line))\n","\n","                    # print(entity_data)\n","\n","                    # Extract required fields\n","                    article_id = entity_data[\"articleID\"]+ \".txt\"  if \".txt\" not in entity_data[\"articleID\"] else entity_data[\"articleID\"]\n","                    entity_name = entity_data[\"entity_name\"]\n","                    start_index = entity_data[\"start_index\"]\n","                    end_index = entity_data[\"end_index\"]\n","                    primary_role = entity_data[\"primary_role\"]\n","                    fine_grained_roles = entity_data[\"fine_grained_roles\"]\n","\n","                    # print(article_id)\n","\n","                    output_line = f\"{article_id}\\t{entity_name}\\t{start_index}\\t{end_index}\\t{primary_role}\\t\" + \"\\t\".join(fine_grained_roles) + \"\\n\"\n","                    outfile.write(output_line)\n","                except json.JSONDecodeError:\n","                    continue\n","\n","            numLines += 1\n","\n","    print(f\"DONE with {numLines} lines\")\n","\n","language = \"RU\"\n","input_file=f\"/content/drive/MyDrive/SemEval_Task10/testdata_ST12/results/{language}/{language}_results.jsonl\"\n","output_file=f\"/content/drive/MyDrive/SemEval_Task10/testdata_ST12/results/{language}/{language}_cleaned.txt\"\n","clean_up_result(input_file, output_file)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9DwwQg-EIBfr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738216409409,"user_tz":300,"elapsed":817,"user":{"displayName":"Prasun Dhungana","userId":"15869599958843435384"}},"outputId":"21fb6b73-f8b3-4b3a-dace-a9a31d6be8b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cleaned results saved back to /content/drive/MyDrive/SemEval_Task10/testdata_ST12/results/RU/RU_cleaned.txt\n","Total corrections made: 16\n","Filtered roles and their counts:\n","- Innocent: 1\n","- Propagandists: 2\n","- ],[Tyrant: 1\n","- ]: 1\n","- >Tyrant: 1\n","- ,: 1\n","- Pressure: 1\n","- Agent: 1\n"]}],"source":["from collections import Counter\n","\n","def clean_results_file(file_path):\n","    fine_grained_roles = {\n","        'Guardian', 'Martyr', 'Peacemaker', 'Rebel', 'Underdog', 'Virtuous',\n","        'Instigator', 'Conspirator', 'Tyrant', 'Foreign Adversary', 'Traitor', 'Spy', 'Saboteur',\n","        'Corrupt', 'Incompetent', 'Terrorist', 'Deceiver', 'Bigot',\n","        'Forgotten', 'Exploited', 'Victim', 'Scapegoat'\n","    }\n","\n","    valid_primary_roles = {'Protagonist', 'Antagonist', 'Innocent'}\n","    corrections = 0  # Total number of corrections made\n","    filtered_roles_counter = Counter()  # To track and count filtered roles\n","    cleaned_lines = []\n","\n","    with open(file_path, 'r') as file:\n","        for line in file:\n","            fields = line.strip().split('\\t')\n","\n","            # Check and correct invalid primary roles\n","            if len(fields) > 4 and fields[4] not in valid_primary_roles:\n","                fields[4] = \"Innocent\"\n","                corrections += 1\n","\n","            # Check and filter invalid fine-grained roles\n","            initial_roles = fields[5:]\n","            filtered_roles = [role for role in initial_roles if re.sub(r'[^a-zA-Z]', '', role) in fine_grained_roles]\n","            invalid_roles = [role for role in initial_roles if role not in fine_grained_roles]\n","\n","            # Increment corrections and update role counter\n","            corrections += len(invalid_roles)\n","            filtered_roles_counter.update(invalid_roles)\n","\n","            # Create cleaned line\n","            cleaned_fields = fields[:5] + filtered_roles\n","            cleaned_lines.append('\\t'.join(cleaned_fields))\n","\n","    # Save cleaned data back to the same file\n","    with open(file_path, 'w') as file:\n","        file.write('\\n'.join(cleaned_lines) + '\\n')\n","\n","    # Display correction summary\n","    print(f\"Cleaned results saved back to {file_path}\")\n","    print(f\"Total corrections made: {corrections}\")\n","    print(\"Filtered roles and their counts:\")\n","    for role, count in filtered_roles_counter.items():\n","        print(f\"- {role}: {count}\")\n","\n","language = \"RU\"\n","file_path = f\"/content/drive/MyDrive/SemEval_Task10/testdata_ST12/results/{language}/{language}_cleaned.txt\"\n","clean_results_file(file_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":182,"status":"ok","timestamp":1738303529579,"user":{"displayName":"Prasun Dhungana","userId":"15869599958843435384"},"user_tz":300},"id":"ILLMK8ls3kis","outputId":"aa0826f3-7425-4641-cbdc-c2220ebef528"},"outputs":[{"output_type":"stream","name":"stdout","text":["NAME            ID              SIZE      MODIFIED       \n","phi4:latest     ac896e5b8b34    9.1 GB    13 seconds ago    \n","llama3.1:70b    711a9e8463af    42 GB     23 minutes ago    \n"]}],"source":["!ollama list"]},{"cell_type":"code","source":["# !pip install ollama\n","# !pip install tiktoken\n","# clear_output()\n","# import os\n","# import json\n","# import jsonlines\n","# import requests\n","# import ollama"],"metadata":{"id":"xn-x3fLRnBFr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import tiktoken\n","# import requests\n","\n","# def count_tokens_tiktoken(prompt, model=\"gpt-4\"):\n","#     \"\"\"\n","#     Count tokens using OpenAI's tiktoken, compatible with Llama3.\n","#     \"\"\"\n","#     enc = tiktoken.encoding_for_model(model)  # Use GPT-4 tokenizer for Llama3\n","#     return len(enc.encode(prompt))"],"metadata":{"id":"bZIN54x5woCi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_aggregated_results(file_paths):\n","    \"\"\"\n","    Load predictions from multiple models and structure them for meta-classification.\n","    \"\"\"\n","    aggregated_data = {}\n","\n","    for file_path in file_paths:\n","        with open(file_path, 'r') as infile:\n","            for line in infile:\n","                fields = line.strip().split('\\t')\n","                article_id = fields[0]\n","                entity_name = fields[1]\n","                start_index = fields[2]\n","                end_index = fields[3]\n","                primary_role = fields[4]\n","                fine_grained_roles = fields[5:]\n","\n","                key = (article_id, entity_name, start_index, end_index)\n","\n","                if key not in aggregated_data:\n","                    aggregated_data[key] = {\"primary_roles\": [], \"fine_grained_roles\": []}\n","\n","                aggregated_data[key][\"primary_roles\"].append(primary_role)\n","                aggregated_data[key][\"fine_grained_roles\"].extend(fine_grained_roles)\n","\n","    return aggregated_data"],"metadata":{"id":"Mj7QDzzynEK8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def meta_classification(article_id, article_text, entity_name, votes, fine_grained_votes, api_url=\"http://0.0.0.0:11434\"):\n","    \"\"\"\n","    Uses Phi4 to determine the best classification based on votes.\n","    \"\"\"\n","\n","    prompt = (\n","        f\"Given the article with ID: {article_id}:\\n'{article_text}'\\n\\n\"\n","        f\"The entity: {entity_name} has been classified by multiple models as:\\n\"\n","        f\"Primary Role Options: {primary_roles}\\n\"\n","        f\"Fine-Grained Role Options: {fine_grained_votes}\\n\\n\"\n","        f\"Based on the given article and model predictions, determine the most appropriate primary_role and fine_grained_roles for each entity\\n\"\n","        f\"Make sure to account for any role that occur multiple times in different models' predictions and give higher emphasis to those.\\n\\n\"\n","        f\"**Primary Roles:**\\n\n","        f\"- **Protagonist**: ['Guardian', 'Martyr', 'Peacemaker', 'Rebel', 'Underdog', 'Virtuous']\\n\"\n","        f\"- **Antagonist**: ['Instigator', 'Conspirator', 'Tyrant', 'Foreign Adversary', 'Traitor', 'Spy', \"\n","        f\"'Saboteur', 'Corrupt', 'Incompetent', 'Terrorist', 'Deceiver', 'Bigot']\\n\"\n","        f\"- **Innocent**: ['Forgotten', 'Exploited', 'Victim', 'Scapegoat']\\n\\n\"\n","        f\"**Important Requirements:**\\n\"\n","        f\"1. Assign exactly one **primary role** ('Protagonist', 'Antagonist', or 'Innocent').\\n\"\n","        f\"2. Assign one or more **fine-grained roles**, strictly from the associated list above.\\n\"\n","        f\"3. Do not invent or use roles that are not listed above.\\n\"\n","        f\"4. Do not leave the primary role or fine-grained roles empty or undefined.\\n\\n\"\n","        f\"**Failure Examples:**\\n\"\n","        f\"- Assigning a primary role not listed (e.g., 'Neutral').\\n\"\n","        f\"- Assigning fine-grained roles not listed (e.g., 'Aggressor', 'Fascist Leader', 'Extremist', 'Scam', 'Expansionist', 'Imperialist', 'Military', 'Propagandist', etc.\\n\"\n","        f\"- Leaving the fine-grained roles empty.\\n\\n\"\n","        f\"Make sure that the classification strictly follows these rules. Your response should only include the assigned **primary role** and the corresponding **fine-grained roles**.\"\"\n",")\n","\n","    response = requests.post(\n","        url=f\"{api_url}/api/generate\",\n","        json={\n","            \"model\": \"phi4\",\n","            \"prompt\": prompt,\n","            \"stream\": False,\n","            \"format\": {\n","                \"type\": \"object\",\n","                \"properties\": {\n","                    \"primary_role\": {\"type\": \"string\"},\n","                    \"fine_grained_roles\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n","                },\n","                \"required\": [\"primary_role\", \"fine_grained_roles\"]\n","            }\n","        }\n","    )\n","\n","    if response.status_code == 200:\n","        try:\n","            output = response.json()\n","            return output['response']\n","        except ValueError as e:\n","            print(f\"Failed for {article_id}: {entity_name}\")\n","            print(\"Error:\", e)\n","    else:\n","        print(f\"API call failed for {article_id}, Status code: {response.status_code}\")\n","\n","    return None"],"metadata":{"id":"oyMUp9k_nLTr"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BuN42b1MIBiO"},"outputs":[],"source":["def process_final_classification(language_folder, base_output_path, file_paths):\n","    \"\"\"\n","    Processes all entities using meta-classification and saves the final results.\n","    \"\"\"\n","    language_code = os.path.basename(language_folder)\n","    os.makedirs(base_output_path, exist_ok=True)\n","\n","    aggregated_data = load_aggregated_results(file_paths)\n","    final_results = []\n","\n","    for (article_id, entity_name, start_index, end_index), data in aggregated_data.items():\n","        primary_role = data[\"primary_role\"]\n","        fine_grained_votes = data[\"fine_grained_roles\"]\n","\n","        # Load the article text\n","        article_path = os.path.join(language_folder, \"subtask-1-documents\", article_id)\n","        with open(article_path, 'r') as file:\n","            article_text = file.read()\n","\n","        # Use large model for final classification\n","        # print(article_id, article_text, entity_name, votes, fine_grained_votes)\n","        final_result = meta_classification(article_id, article_text, entity_name, votes, fine_grained_votes)\n","\n","        # break\n","\n","        if final_result:\n","            final_result = json.loads(final_result)\n","            final_result[\"articleID\"] = article_id\n","            final_result[\"entity_name\"] = entity_name\n","            final_result[\"start_index\"] = start_index\n","            final_result[\"end_index\"] = end_index\n","            final_results.append(final_result)\n","\n","    # Save results to a text file\n","    output_file = os.path.join(base_output_path, f\"{language_code}_final_results.jsonl\")\n","    with jsonlines.open(output_file, mode='w') as writer:\n","        writer.write_all(final_results)\n","\n","    print(f\"Final classifications for {language_code} saved to {output_file}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"usK5rW2iIBkp"},"outputs":[],"source":["def main():\n","    base_path = \"/content/drive/MyDrive/SemEval_Task10/testdata_ST12/\"\n","    base_output_path = \"/content/drive/MyDrive/SemEval_Task10/testdata_ST12/Test_Results_Final\"\n","\n","    language = \"EN\"\n","    language_folder = os.path.join(base_path, language)\n","\n","    file_paths = [\n","        f\"/content/drive/MyDrive/SemEval_Task10/testdata_ST12/Test_Results/Gemma2/{language}_cleaned.txt\",\n","        f\"/content/drive/MyDrive/SemEval_Task10/testdata_ST12/Test_Results/Llama3.1-8b/{language}_cleaned.txt\",\n","        f\"/content/drive/MyDrive/SemEval_Task10/testdata_ST12/Test_Results/Mistral-7b/{language}_cleaned.txt\",\n","        f\"/content/drive/MyDrive/SemEval_Task10/testdata_ST12/Test_Results/Phi4/{language}_cleaned.txt\"\n","    ]\n","\n","    process_final_classification(language_folder, base_output_path, file_paths)\n","\n","main()"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","provenance":[],"authorship_tag":"ABX9TyNJ8PeyA4p+I9X6UT2kcWUT"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}